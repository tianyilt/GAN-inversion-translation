\section{挑战与未来方向}
\label{sec:outlook}

\noindent\textbf{理论认识.} 
尽管在实际应用中取得了成功，但对GAN逆向的理论认识仍然缺乏.
逆向可以看作是非线性等效的降维,通常由PCA执行~\cite{eric2020GANSpace}. 
数据中的非线性结构可以被紧凑地表示，而这个几何结构需要使用非线性统计工具~\cite{kuhnel2018latent}, 黎曼流形, 和局部线性方法. 
完善的相关理论有助于从不同角度从神经网络的权值(参数)或隐空间对GAN逆向进行理论理解.
例如，我们可以将GAN逆向表示为将信号分解成分量(矩阵分解问题)并使用非线性因子分析(FA)~\cite{harman1976modern}, 独立成分分析 (ICA)~\cite{davies2007source}, 潜在狄利克雷分布 (LDA)~\cite{hoffman2010online,blei2003latent} 来分解网络权值，寻找隐空间的可解释方向. 

\vspace{1mm}
\noindent\textbf{Inversion Type.} 
除了GAN逆向之外，还开发了一些基于编解码器结构的生成模型逆向方法.
IIN 方法~\cite{esser2020invertible} 学习变分自动编码器(VAE)的可逆解耦解释~\cite{kingma2013auto}. 
Zhu~\etal~\cite{zhu2019lia} 开发潜在的可逆的自动编码器方法来学习人脸图像的解耦表示，从中可以根据属性编辑内容. 
LaDDer方法~\cite{Lin2020LaDDer} 采用基于生成先验(包括可加的VAE和超先验的混合)的元嵌入方法，将预训练的VAE的隐空间投射到低维的隐空间，在低维的隐空间中使用多个VAE模型形成层次表示.
探索如何将GAN逆向和编解码网络逆向结合起来是有益的，这样我们就可以充分利用这两个网络的优点.

\vspace{1mm}
\noindent\textbf{域泛化.}
如第~\ref{sec:applications}节所述, GAN逆向在风格迁移和图像恢复等跨域应用中被证明是有效的，这表明预先训练的模型学习了域内不可知的特征. 
来自不同领域的图像可以被倒置到相同的隐空间，从中可以得到有效的度量. 
在GAN框架内,图像恢复和图像分割等多任务方法可以协同利用视觉线索~\cite{xia2019adverse}, 或者是语义分割和深度估计~\cite{Nekrasov2019joint,zhan2019joint}.
开发有效的、一致的方法来转换中间共享表示，使我们能够在一个统一的框架下处理不同的视觉任务是具有挑战性的，但也是值得的. 

\vspace{1mm}
\noindent\textbf{场景表示.}
GAN 逆向的方法~\cite{abdal2020styleflow,voynov2020latent} 可以处理几何 (如缩放, 平移, 和旋转), 材质(\eg, 背景模糊和锐化) 以及颜色(如光照和饱和).
这种能力表明，在大规模数据集上预先训练的GAN模型已经从真实场景中学习了一些物理信息.
隐式的神经表示性学习~\cite{chen2019learning,tucker2020single,rajeswar2020pix2shape}, 在3D社区中，最近的一个趋势是学习3D形状或场景的隐式函数，并允许控制场景属性，如照明、相机参数、姿态、几何形状、外观和语义结构.
这已经被用来进行立体动态捕捉~\cite{chen2020free,liu2020neural,lombardi2019neural}, 新颖视角合成~\cite{martin2020nerf,martin2020nerf}, 人脸形状生成~\cite{wu2020unsupervised}, 对象建模~\cite{nguyen2020blockgan,kato2019self}, 以及人体建模~\cite{zheng2020pamir,bhatnagar2020combining,he2020geo,saito2020pifuhd}.
最近StyleRig 方法~\cite{tewari2020stylerig} 基于三维变形模型(3DMM)语义参数和StyleGAN~\cite{karras2019style}的输入参数进行训练~\cite{egger20203d} .
将预先训练过的GAN的这种隐式表示转化为三维重建，开启了一个有趣的研究方向, 比如用 StyleGAN~\cite{karras2019style} 进行人脸建模或延时视频生成.

\vspace{1mm}
\noindent\textbf{精准控制.} 
GAN 逆向可以用来为图像操作寻找方向，同时保留身份和其他属性~\cite{abdal2020styleflow,shen2020interpreting}.
然而, 还需要进行一些调优，以实现所需的精确细粒度控制的粒度, 比如 目光重定向~\cite{ganin2016deepwarp,wood2018gaze,he2019gaze,xia2020gaze}, 重新光照~\cite{zhou2019deep,sun2019single,zhang2020portrait} 以及 连续的视角控制~\cite{chen2019monocular}.
这些任务需要细粒度的控制, 比如$1^{\circ}$的相机视角或者目光朝向角度. 
目前的GAN逆向方法无法解决这一问题，需要更多的努力来轻松完成这些任务，比如创造更多的解耦的隐空间，发现更多可解释的方向.

\vspace{1mm}
\noindent\textbf{多模态逆向.}
现有的GAN逆向方法主要是图像逆向.
然而, 生成模型的最新进展超出了图像领域, 比如 GPT-3 语言模型~\cite{brown2020gpt3} 以及用来音频合成的WaveNet ~\cite{oord2016wavenet}. 
在不同的大规模数据集上训练，这些复杂的深度神经网络已经被证明能够代表广泛的不同内容、风格、情感和主题.
将GAN逆向技术应用于这些不同的模态，可以为模态转换等任务提供一个新的视角. 
此外，还有用于多模态生成或翻译的GAN模型~\cite{li2019control,jia2018speaker,prajwal2020speech}. 
将这样的GAN模型转化为创造新颖内容、行为和交互的多模态表示是非常有益的.

\vspace{1mm}
\noindent\textbf{评价标准.}
感知质量指标，能够更好地评价照片真实感和多样性图像或一致性的原始图像，仍有待探索。评价主要集中在照片的真实感上，用真实图像训练的分类~\cite{bau2019seeing}和分割~\cite{voynov2020latent}模型来判断生成图像的分布是否与真实图像一致. 
然而，目前还缺乏有效的评估工具来评估模型预测结果与人类预期结果方向的差异，或更直接地测量逆向的隐向量.